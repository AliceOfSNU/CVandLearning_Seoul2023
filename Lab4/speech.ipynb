{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "CMUdict_ARPAbet = {\n",
    "    \"\" : \" \",\n",
    "    \"[SIL]\": \"-\", \"NG\": \"G\", \"F\" : \"f\", \"M\" : \"m\", \"AE\": \"@\",\n",
    "    \"R\"    : \"r\", \"UW\": \"u\", \"N\" : \"n\", \"IY\": \"i\", \"AW\": \"W\",\n",
    "    \"V\"    : \"v\", \"UH\": \"U\", \"OW\": \"o\", \"AA\": \"a\", \"ER\": \"R\",\n",
    "    \"HH\"   : \"h\", \"Z\" : \"z\", \"K\" : \"k\", \"CH\": \"C\", \"W\" : \"w\",\n",
    "    \"EY\"   : \"e\", \"ZH\": \"Z\", \"T\" : \"t\", \"EH\": \"E\", \"Y\" : \"y\",\n",
    "    \"AH\"   : \"A\", \"B\" : \"b\", \"P\" : \"p\", \"TH\": \"T\", \"DH\": \"D\",\n",
    "    \"AO\"   : \"c\", \"G\" : \"g\", \"L\" : \"l\", \"JH\": \"j\", \"OY\": \"O\",\n",
    "    \"SH\"   : \"S\", \"D\" : \"d\", \"AY\": \"Y\", \"S\" : \"s\", \"IH\": \"I\",\n",
    "    \"[SOS]\": \"[SOS]\", \"[EOS]\": \"[EOS]\"\n",
    "}\n",
    "\n",
    "CMUdict = list(CMUdict_ARPAbet.keys())\n",
    "ARPAbet = list(CMUdict_ARPAbet.values())\n",
    "\n",
    "PHONEMES = CMUdict[:-2]\n",
    "LABELS = ARPAbet[:-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create dataset from data  ../../data/ARPAbet_kaggle/train-clean-100\n",
      "\ttotal mfcc cnt:  28539\n",
      "\ttotal transcript cnt:  28539\n",
      "create dataset from data  ../../data/ARPAbet_kaggle/dev-clean\n",
      "\ttotal mfcc cnt:  2703\n",
      "\ttotal transcript cnt:  2703\n"
     ]
    }
   ],
   "source": [
    "import dataset\n",
    "from dataset import AudioDataset\n",
    "\n",
    "# probably want to collect some RAM before we go.\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "train_data = AudioDataset('train-clean-100', data_dir=\"../../data/ARPAbet_kaggle\")\n",
    "val_data = AudioDataset('dev-clean', data_dir=\"../../data/ARPAbet_kaggle\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "one observation to make is that each trancript\n",
    "starts with [SIL] and ends with [SIL]. There are moments of silence at the beginning and end of each recording, which should be mapped to this token.\n",
    "\n",
    "The \\<sos\\> and \\<eos\\> tokens have been removed in dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1174, 28) float32\n",
      "[ 1 26  8 37 15 20 40 19 16  5 28  9 15 39 15 18 26  4 39 23  5  8 39 26\n",
      " 17 25  7  4 38 23  1 40  3  1 26 11  5  8 26 27 17 15 11 40  2 23 15  8\n",
      " 26 11  4 38  8 37 26  8 37  8 14 23  7  4 26 19 26 11 26 16 10 39 20 38\n",
      "  3 23  7 27  9 40  8 16 25  7  4 26  8  1 16  5 11 32 40 11 26  8 30 26\n",
      " 39 24  8 23  6 26 33  3 40 32 25 15 26 11 30 40 39 23 31  6  9  1 33 24\n",
      " 39 18 15 39 15  9 26 23 24  8 36 26  8  1]\n",
      "[SIL] AH N D ER W IH CH HH AE P IY ER S ER K AH M S T AE N S AH Z Y UW M AY T [SIL] IH F [SIL] AH V AE N AH B Z ER V IH NG T ER N AH V M AY N D AH N D N AA T UW M AH CH AH V AH HH AW S W AY F T UW B IY IH N HH Y UW M AH N [SIL] HH AE V G IH V AH N DH AH S EH N T R AH L F IH G Y ER AH V DH IH S T AO R IY [SIL] L EH S K ER S ER IY AH T EH N SH AH N [SIL]\n",
      "(1463, 28) float32\n",
      "[ 1 26  8 37 26 33 38 23  8 40  2 33 38 18  4  7 11  4 26  8 23  1 39 26\n",
      "  4 20 12 37 18 31 33 40 23 33 26 18  1 16  9  4  5  8 26 34 37 23  7 39\n",
      " 21 11 16 40  4 39 24 33  3  1 40  8 30 40 39 20 21  1 20  9 20 15 18 23\n",
      " 26 28 26 27 10 23  7 16 26  8 37  6 26 37  3  9 23  1 27 26 23 30 24  8\n",
      " 20  9 18 21  4  1 26 28 14  8 39 26 19 26 33  5 27 15 40  8 29 26 11 25\n",
      " 31  8 40  2 19  5 39  4 17  1 26  8 37 13 28 26  8 26 27 38 39 26 17  1]\n",
      "[SIL] AH N D AH L AY T N IH NG L AY K M UW V M AH N T [SIL] S AH M W UH D K AO L IH T L AH K [SIL] HH IY M AE N AH JH D T UW S EY V HH IH M S EH L F [SIL] IH N DH IH S W EY [SIL] W IY W ER K T AH P AH B AW T UW HH AH N D R AH D F IY T [SIL] B AH T DH EH N W IY K EY M [SIL] AH P AA N S AH CH AH L AE B ER IH N TH AH V Y AO N IH NG CH AE S M Z [SIL] AH N D OW P AH N AH B AY S AH Z [SIL]\n"
     ]
    }
   ],
   "source": [
    "mfcc,  transcript = train_data[0]\n",
    "print(mfcc.shape, mfcc.dtype)\n",
    "print(transcript)\n",
    "string = [train_data.idx_to_str(x) for x in transcript]\n",
    "print(\" \".join(string))\n",
    "\n",
    "mfcc,  transcript = train_data[1]\n",
    "print(mfcc.shape, mfcc.dtype)\n",
    "print(transcript)\n",
    "string = [train_data.idx_to_str(x) for x in transcript]\n",
    "print(\" \".join(string))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset samples = 28539, batches = 445\n",
      "torch.Size([64, 1611, 28]) torch.Size([64, 226]) torch.Size([64]) torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 64\n",
    "train_loader =  DataLoader(\n",
    "            train_data,\n",
    "            batch_size=batch_size,\n",
    "            drop_last=True,\n",
    "            shuffle=True,\n",
    "            collate_fn=train_data.collate_fn\n",
    ")\n",
    "\n",
    "\n",
    "print(\"Train dataset samples = {}, batches = {}\".format(train_data.__len__(), len(train_loader)))\n",
    "\n",
    "# sanity check\n",
    "for data in train_loader:\n",
    "    x, y, lx, ly = data\n",
    "    print(x.shape, y.shape, lx.shape, ly.shape)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1671, 28]) torch.Size([64, 281]) torch.Size([64]) torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "from model import ASRModel\n",
    "from defines import PHONEMES\n",
    "\n",
    "model = ASRModel(\n",
    "    input_size = 28, \n",
    "    embed_size= 64,\n",
    "    output_size = len(PHONEMES)\n",
    ")\n",
    "for data in train_loader:\n",
    "    x, y, lx, ly = data\n",
    "    decoder_out, encoder_lens = model.forward(x, lx)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n",
      "[' ', '-', 'G', 'f', 'm', '@', 'r', 'u', 'n', 'i', 'W', 'v', 'U', 'o', 'a', 'R', 'h', 'z', 'k', 'C', 'w', 'e', 'Z', 't', 'E', 'y', 'A', 'b', 'p', 'T', 'D', 'c', 'g', 'l', 'j', 'O', 'S', 'd', 'Y', 's', 'I']\n",
      "[SOS]AND THE POOR SILLY THINGS RUFFLED UP THEIR FEATHERS AND LOOKED MISERABLE AS ONLY A LITTLE BIRD CAN LOOK WHEN IT IS UNHAPPY[EOS]\n",
      "[SOS]HE THOUGHT IT WAS A LAST BURST OF ENERGY HE KNEW HOW CLOSE THEY BOTH WERE TO EXHAUSTION[EOS]\n",
      "[SOS]WE WERE INURED TO PRIVATIONS AND HARDSHIPS HAD BEEN UPON EVERY MARCH IN EVERY BATTLE IN EVERY SKIRMISH IN EVERY ADVANCE IN EVERY RETREAT IN EVERY VICTORY IN EVERY DEFEAT[EOS]\n",
      "[SOS]THIS WAS THE OLD ESTABLISHMENT OF URSUS ITS PROPORTIONS AUGMENTED BY SUCCESS AND IMPROVED FROM A WRETCHED BOOTH INTO A THEATRE[EOS]\n",
      "[SOS]LETTY FINDING HERSELF NOT QUITE EQUAL TO THE EMERGENCY CAME IN HER TURN TO CALL MARY SHE WENT AS QUIETLY AS IF SHE WERE LEAVING A TIRESOME VISITOR[EOS]\n",
      "[SOS]BUT EARNEST AS THE FATHER WAS IN WATCHING THE YET LIVING HE HAD EYES AND EARS FOR ALL THAT CONCERNED THE DEAD AND SPRANG GENTLY UP AND TOOK HIS DEAD SON ON HIS HARD COUCH IN HIS ARMS WITH TENDER STRENGTH AND CARRIED HIM UPSTAIRS AS IF AFRAID OF WAKENING HIM[EOS]\n",
      "[SOS]BUT VIGOUR RETURNED TO HIM BEFORE HE HAD WELL REACHED THE DOOR AND HE SHOWED SOME OF HIS OLD SPIRIT AS HE THANKED MISS CLARKE AND TURNED TO TAKE THE ELEVATOR[EOS]\n",
      "[SOS]I AM SURPRISED HOWEVER THAT THE BOOK AT WHICH SUCH AN EXAMPLE OF THE SPECIOUS MISUSE OF ANALOGY WOULD SEEM MOST NATURALLY LEVELLED SHOULD HAVE OCCURRED TO NO REVIEWER NEITHER SHALL I MENTION THE NAME OF THE BOOK HERE THOUGH I SHOULD FANCY THAT THE HINT GIVEN WILL SUFFICE[EOS]\n",
      "[SOS]I MIGHT BE TOLD THAT IF I HAD WISHED TO FOLLOW THE RULES OF PURE MORALITY I OUGHT EITHER TO HAVE DECLINED INTIMATE INTERCOURSE WITH THEM OR TO HAVE UNDECEIVED THEM[EOS]\n",
      "[SOS]IT'S LIKE YOUR HORSE SUDDENLY FALLING DEAD UNDER YOU IN THE MIDST OF AN UNINHABITED AND THIRSTY PLAIN[EOS]\n",
      "[' ', '-', '@', 'A', 'C', 'D', 'E', 'G', 'I', 'O', 'R', 'S', 'T', 'U', 'W', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "print(len(LABELS))\n",
    "print(LABELS)\n",
    "\n",
    "for i in range(10):\n",
    "    mfcc,  transcript = val_data[i]\n",
    "    sent = [val_data.int_to_str(s) for s in transcript]\n",
    "    print(''.join(sent))\n",
    "\n",
    "print(sorted(LABELS))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lowergcc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
